# Phase 1 - Module 2: Industrial Energy & Cyber Intelligence Backend

Welcome to **Phase 1 - Module 2** of our Industrial Energy & Cyber Intelligence Platform! This module is focused on **Backend Development** for anomaly detection, root cause analysis, and chatbot integration using **FastAPI** and **Docker**.

---

## ðŸš€ Overview
This backend module implements a scalable, **Onion Architecture** for real-time monitoring of:

- âš¡ **Energy Anomalies** (using Steel Industry Energy Dataset)
- ðŸ­ **Machine / Sensor Anomalies** (Industrial IoT Fault Dataset)
- ðŸ” **Cyber Anomalies** (SWaT ICS Dataset)

It supports **parallel development** for multiple team members, integrates trained models, and exposes **API endpoints** for frontend and chatbot consumption.

---

## ðŸ“‚ Directory Structure
```
backend/
â”‚
â”œâ”€ domain/          # Core business logic & entities
â”‚   â”œâ”€ energy.py
â”‚   â”œâ”€ machine.py
â”‚   â””â”€ cyber.py
â”‚
â”œâ”€ services/        # Application layer for orchestrating logic
â”‚   â”œâ”€ energy_service.py
â”‚   â”œâ”€ machine_service.py
â”‚   â””â”€ cyber_service.py
â”‚
â”œâ”€ infrastructure/  # FastAPI endpoints + Docker setup
â”‚   â”œâ”€ main.py
â”‚   â”œâ”€ routes/
â”‚   â””â”€ models_loader.py
â”‚
â”œâ”€ docker/
â”‚   â”œâ”€ Dockerfile_energy
â”‚   â”œâ”€ Dockerfile_cyber
â”‚   â””â”€ docker-compose.yml
â”‚
â”œâ”€ models/          # Trained ML models
â”œâ”€ datasets/        # CSV datasets
â””â”€ requirements.txt
```

---

## ðŸ› ï¸ Features

### Energy & Machine Module (Member 1)
- Load & preprocess Steel Industry Energy Dataset and Industrial IoT Fault Dataset
- Train LSTM / Autoencoder models for anomaly detection
- Expose API endpoints: `/anomalies/energy` & `/anomalies/machine`
- Compute **root cause scores** and provide structured JSON responses

### Cyber & Chatbot Module (Member 2)
- Load & preprocess SWaT dataset
- Train LSTM / GRU / VAE models for cyber anomaly detection
- Expose API endpoints: `/anomalies/cyber` & `/chatbot/query`
- Aggregate anomalies from energy & machine modules for unified response

### Integration & Deployment
- Each module runs in a **Docker container**
- `docker-compose.yml` manages multi-container orchestration
- Frontend interacts seamlessly via REST APIs

---

## ðŸ—ï¸ Technology Stack
- **Backend Framework:** FastAPI
- **Modeling:** PyTorch / TensorFlow
- **Docker:** Containerized services
- **Datasets:**
  - Steel Industry Energy Dataset
  - Industrial IoT Fault Detection Dataset
  - SWaT ICS Dataset
- **Frontend Integration:** API endpoints exposed for chatbot/dashboard

---

## âš¡ How to Run
1. Clone the repository
2. Navigate to `backend/docker`
3. Build and run containers:
```bash
docker-compose up --build
```
4. Access API endpoints:
```
GET /anomalies/energy
GET /anomalies/machine
GET /anomalies/cyber
POST /chatbot/query
```

---

## ðŸ“Œ Notes & Guidelines
- Ensure all datasets are placed in `/datasets`
- Trained models should be in `/models`
- Follow the **Onion Architecture principles** for adding new services or logic
- Use shared **JSON schema** for consistent responses across modules

---

## ðŸŽ¯ Goals for Phase 1
1. Real-time anomaly detection for energy, machine, and cyber modules
2. Root cause analysis integrated into API responses
3. Chatbot query system that aggregates anomalies
4. Fully containerized backend ready for frontend integration

---

## ðŸ’¡ Contributors
- **Member 1:** Energy & Machine anomaly module
- **Member 2:** Cyber anomaly & Chatbot module
- **Member 3:** Frontend dashboard integration

---

## ðŸ“š References
1. Steel Industry Energy Dataset - [Kaggle](https://www.kaggle.com/datasets/csafrit2/steel-industry-energy-consumption) | [UCI Mirror](https://archive.ics.uci.edu/dataset/851/steel%2B)
2. Industrial IoT Fault Detection Dataset - [Kaggle](https://www.kaggle.com/datasets/ziya07/industrial-iot-fault-detection-dataset/data?utm_source=chatgpt.com)
3. SWaT ICS Dataset - [Kaggle](https://www.kaggle.com/datasets/vishala28/swat-dataset-secure-water-treatment-system?utm_source=chatgpt.com)

---

> ðŸ’¬ This README is designed for Phase 1, Module 2 of the project. Follow this structure for scalable development and smooth integration with frontend and other backend services.
